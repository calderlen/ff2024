{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 19:25:12.463429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 19:25:12.475971: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 19:25:12.479483: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 19:25:12.499144: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 19:25:13.309712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from modelDesign import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/player_stats.csv')\n",
    "df = df.sort_values(by=['player_id', 'season', 'week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calder/Documents/ff2024/dataPreparation.py:31: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[numeric_cols] = df[numeric_cols].applymap(lambda x: np.nan if np.isinf(x) else x)\n",
      "/home/calder/Documents/ff2024/dataPreparation.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 3\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "df = featureEngineering(df)\n",
    "\n",
    "qb_df_features, qb_df_target, rb_df_features, rb_df_target, wr_df_features, wr_df_target, te_df_features, te_df_target = cleanData(df)\n",
    "\n",
    "X_qb, y_qb = create_sequences(qb_df_features.values, qb_df_target.values, sequence_length)\n",
    "X_rb, y_rb = create_sequences(rb_df_features.values, rb_df_target.values, sequence_length)\n",
    "X_wr, y_wr = create_sequences(wr_df_features.values, wr_df_target.values, sequence_length)\n",
    "X_te, y_te = create_sequences(te_df_features.values, te_df_target.values, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_id               object\n",
       "player_name             object\n",
       "player_display_name     object\n",
       "position                object\n",
       "position_group          object\n",
       "                        ...   \n",
       "moving_avg_fp_3w       float64\n",
       "fp_diff_wow            float64\n",
       "fp_pct_change_2w       float64\n",
       "fp_momentum_3w         float64\n",
       "fp_acceleration        float64\n",
       "Length: 65, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all types of data in df\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>player_display_name</th>\n",
       "      <th>position</th>\n",
       "      <th>position_group</th>\n",
       "      <th>headshot_url</th>\n",
       "      <th>recent_team</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>season_type</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_passing_yards</th>\n",
       "      <th>rolling_fantasy_points</th>\n",
       "      <th>rolling_avg_fantasy_points</th>\n",
       "      <th>fp_rolling_std_4w</th>\n",
       "      <th>lag_fantasy_points</th>\n",
       "      <th>moving_avg_fp_3w</th>\n",
       "      <th>fp_diff_wow</th>\n",
       "      <th>fp_pct_change_2w</th>\n",
       "      <th>fp_momentum_3w</th>\n",
       "      <th>fp_acceleration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_id</th>\n",
       "      <th>season</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00-0000003</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1999</th>\n",
       "      <th>0</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1999</td>\n",
       "      <td>2</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>12.700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>8.900</td>\n",
       "      <td>5.374012</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1999</td>\n",
       "      <td>7</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>6.298412</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-0.984252</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1999</td>\n",
       "      <td>8</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>5.375</td>\n",
       "      <td>5.292369</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-0.313725</td>\n",
       "      <td>-12.5</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">00-0039165</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2023</th>\n",
       "      <th>128868</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>14</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.181818</td>\n",
       "      <td>8.700</td>\n",
       "      <td>4.821480</td>\n",
       "      <td>15.9</td>\n",
       "      <td>9.533333</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.304348</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128869</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>15</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.150000</td>\n",
       "      <td>8.350</td>\n",
       "      <td>5.105879</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.833333</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>-0.172414</td>\n",
       "      <td>9.7</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128870</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.876923</td>\n",
       "      <td>7.025</td>\n",
       "      <td>6.181896</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.433333</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-0.899371</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128871</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>5.475</td>\n",
       "      <td>7.272494</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.083333</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128872</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>18</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.473333</td>\n",
       "      <td>2.525</td>\n",
       "      <td>2.385197</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.766667</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128873 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           player_id   player_name    player_display_name  \\\n",
       "player_id  season                                                           \n",
       "00-0000003 1999   0       00-0000003           NaN  Abdul-Karim al-Jabbar   \n",
       "                  1       00-0000003           NaN  Abdul-Karim al-Jabbar   \n",
       "                  2       00-0000003           NaN  Abdul-Karim al-Jabbar   \n",
       "                  3       00-0000003           NaN  Abdul-Karim al-Jabbar   \n",
       "                  4       00-0000003           NaN  Abdul-Karim al-Jabbar   \n",
       "...                              ...           ...                    ...   \n",
       "00-0039165 2023   128868  00-0039165  Z.Charbonnet        Zach Charbonnet   \n",
       "                  128869  00-0039165  Z.Charbonnet        Zach Charbonnet   \n",
       "                  128870  00-0039165  Z.Charbonnet        Zach Charbonnet   \n",
       "                  128871  00-0039165  Z.Charbonnet        Zach Charbonnet   \n",
       "                  128872  00-0039165  Z.Charbonnet        Zach Charbonnet   \n",
       "\n",
       "                         position position_group  \\\n",
       "player_id  season                                  \n",
       "00-0000003 1999   0            RB             RB   \n",
       "                  1            RB             RB   \n",
       "                  2            RB             RB   \n",
       "                  3            RB             RB   \n",
       "                  4            RB             RB   \n",
       "...                           ...            ...   \n",
       "00-0039165 2023   128868       RB             RB   \n",
       "                  128869       RB             RB   \n",
       "                  128870       RB             RB   \n",
       "                  128871       RB             RB   \n",
       "                  128872       RB             RB   \n",
       "\n",
       "                                                               headshot_url  \\\n",
       "player_id  season                                                             \n",
       "00-0000003 1999   0                                                     NaN   \n",
       "                  1                                                     NaN   \n",
       "                  2                                                     NaN   \n",
       "                  3                                                     NaN   \n",
       "                  4                                                     NaN   \n",
       "...                                                                     ...   \n",
       "00-0039165 2023   128868  https://static.www.nfl.com/image/private/f_aut...   \n",
       "                  128869  https://static.www.nfl.com/image/private/f_aut...   \n",
       "                  128870  https://static.www.nfl.com/image/private/f_aut...   \n",
       "                  128871  https://static.www.nfl.com/image/private/f_aut...   \n",
       "                  128872  https://static.www.nfl.com/image/private/f_aut...   \n",
       "\n",
       "                         recent_team  season  week season_type  ...  \\\n",
       "player_id  season                                               ...   \n",
       "00-0000003 1999   0              MIA    1999     1         REG  ...   \n",
       "                  1              MIA    1999     2         REG  ...   \n",
       "                  2              MIA    1999     4         REG  ...   \n",
       "                  3              CLE    1999     7         REG  ...   \n",
       "                  4              CLE    1999     8         REG  ...   \n",
       "...                              ...     ...   ...         ...  ...   \n",
       "00-0039165 2023   128868         SEA    2023    14         REG  ...   \n",
       "                  128869         SEA    2023    15         REG  ...   \n",
       "                  128870         SEA    2023    16         REG  ...   \n",
       "                  128871         SEA    2023    17         REG  ...   \n",
       "                  128872         SEA    2023    18         REG  ...   \n",
       "\n",
       "                         rolling_passing_yards  rolling_fantasy_points  \\\n",
       "player_id  season                                                        \n",
       "00-0000003 1999   0                        0.0                0.000000   \n",
       "                  1                        0.0               12.700000   \n",
       "                  2                        0.0                8.900000   \n",
       "                  3                        0.0                6.000000   \n",
       "                  4                        0.0                5.375000   \n",
       "...                                        ...                     ...   \n",
       "00-0039165 2023   128868                   0.0                5.181818   \n",
       "                  128869                   0.0                5.150000   \n",
       "                  128870                   0.0                4.876923   \n",
       "                  128871                   0.0                4.500000   \n",
       "                  128872                   0.0                4.473333   \n",
       "\n",
       "                          rolling_avg_fantasy_points  fp_rolling_std_4w  \\\n",
       "player_id  season                                                         \n",
       "00-0000003 1999   0                            0.000           0.000000   \n",
       "                  1                           12.700           0.000000   \n",
       "                  2                            8.900           5.374012   \n",
       "                  3                            6.000           6.298412   \n",
       "                  4                            5.375           5.292369   \n",
       "...                                              ...                ...   \n",
       "00-0039165 2023   128868                       8.700           4.821480   \n",
       "                  128869                       8.350           5.105879   \n",
       "                  128870                       7.025           6.181896   \n",
       "                  128871                       5.475           7.272494   \n",
       "                  128872                       2.525           2.385197   \n",
       "\n",
       "                          lag_fantasy_points  moving_avg_fp_3w  fp_diff_wow  \\\n",
       "player_id  season                                                             \n",
       "00-0000003 1999   0                      0.0          0.000000          0.0   \n",
       "                  1                     12.7         12.700000          0.0   \n",
       "                  2                      5.1          8.900000         -7.6   \n",
       "                  3                      0.2          6.000000         -4.9   \n",
       "                  4                      3.5          2.933333          3.3   \n",
       "...                                      ...               ...          ...   \n",
       "00-0039165 2023   128868                15.9          9.533333         10.1   \n",
       "                  128869                 4.8          8.833333        -11.1   \n",
       "                  128870                 1.6          7.433333         -3.2   \n",
       "                  128871                -0.4          2.000000         -2.0   \n",
       "                  128872                 4.1          1.766667          4.5   \n",
       "\n",
       "                          fp_pct_change_2w  fp_momentum_3w  fp_acceleration  \n",
       "player_id  season                                                            \n",
       "00-0000003 1999   0               0.000000             0.0              0.0  \n",
       "                  1               0.000000             0.0              0.0  \n",
       "                  2               0.000000             0.0              0.0  \n",
       "                  3              -0.984252            -7.6              0.0  \n",
       "                  4              -0.313725           -12.5              2.7  \n",
       "...                                    ...             ...              ...  \n",
       "00-0039165 2023   128868          1.304348             4.5             -1.8  \n",
       "                  128869         -0.172414             9.7             11.2  \n",
       "                  128870         -0.899371            -2.1            -21.2  \n",
       "                  128871         -1.083333            -4.2              7.9  \n",
       "                  128872          1.562500           -16.3              1.2  \n",
       "\n",
       "[128873 rows x 65 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_qb.shape\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'qb': [],\n",
    "    'rb': [],\n",
    "    'wr': [],\n",
    "    'te': []\n",
    "}\n",
    "\n",
    "for X, y, key in [(X_qb, y_qb, 'qb'), \n",
    "                  (X_rb, y_rb, 'rb'), \n",
    "                  (X_wr, y_wr, 'wr'), \n",
    "                  (X_te, y_te, 'te')]:\n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(process_data(X, y, tscv)):\n",
    "        datasets[key].append({\n",
    "            'X_train': X_train,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_test': y_test\n",
    "        })\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724970785.275281  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724970785.343563  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724970785.346357  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724970785.349300  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724970785.351652  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724970785.354303  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724970785.502835  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724970785.504718  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724970785.506198  332618 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-29 18:33:05.508212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5467 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "/home/calder/Documents/ff2024/ff24/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7a092874f370>' to a shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras_tuner\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Instantiate the tuner\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tuner \u001b[38;5;241m=\u001b[39m \u001b[43mkt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomSearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuildModelGRU\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutions_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtuning\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgru_tuning\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Perform hyperparameter tuning\u001b[39;00m\n\u001b[1;32m     14\u001b[0m tuner\u001b[38;5;241m.\u001b[39msearch(X_train, y_train, validation_data\u001b[38;5;241m=\u001b[39m(x_val, y_val), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/keras_tuner/src/tuners/randomsearch.py:174\u001b[0m, in \u001b[0;36mRandomSearch.__init__\u001b[0;34m(self, hypermodel, objective, max_trials, seed, hyperparameters, tune_new_entries, allow_new_entries, max_retries_per_trial, max_consecutive_failed_trials, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m seed\n\u001b[1;32m    164\u001b[0m oracle \u001b[38;5;241m=\u001b[39m RandomSearchOracle(\n\u001b[1;32m    165\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m    166\u001b[0m     max_trials\u001b[38;5;241m=\u001b[39mmax_trials,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    172\u001b[0m     max_consecutive_failed_trials\u001b[38;5;241m=\u001b[39mmax_consecutive_failed_trials,\n\u001b[1;32m    173\u001b[0m )\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:122\u001b[0m, in \u001b[0;36mTuner.__init__\u001b[0;34m(self, oracle, hypermodel, max_model_size, optimizer, loss, metrics, distribution_strategy, directory, project_name, logger, tuner_id, overwrite, executions_per_trial, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hypermodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial \u001b[38;5;129;01mis\u001b[39;00m Tuner\u001b[38;5;241m.\u001b[39mrun_trial:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived `hypermodel=None`. We only allow not specifying \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`hypermodel` if the user defines the search space in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Tuner.run_trial()` by subclassing a `Tuner` class without \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing a `HyperModel` instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m     )\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_size \u001b[38;5;241m=\u001b[39m max_model_size\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m optimizer\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:132\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, oracle, hypermodel, directory, project_name, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreload()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# Only populate initial space if not reloading.\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_populate_initial_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Run in distributed mode.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dist_utils\u001b[38;5;241m.\u001b[39mhas_chief_oracle() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dist_utils\u001b[38;5;241m.\u001b[39mis_chief_oracle():\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# Proxies requests to the chief oracle.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Avoid import at the top, to avoid inconsistent protobuf versions.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:192\u001b[0m, in \u001b[0;36mBaseTuner._populate_initial_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mdeclare_hyperparameters(hp)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_activate_all_conditions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:149\u001b[0m, in \u001b[0;36mBaseTuner._activate_all_conditions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m hp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_space()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_space(hp)\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# Update the recorded scopes.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ff2024/modelDesign.py:33\u001b[0m, in \u001b[0;36mbuildModelGRU\u001b[0;34m(input_shape, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, seed, return_sequences, return_state, go_backwards, stateful, unroll, reset_after, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Add GRU layer\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGRU\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecurrent_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecurrent_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_initializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecurrent_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivity_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivity_regularizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecurrent_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias_constraint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias_constraint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecurrent_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgo_backwards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgo_backwards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstateful\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstateful\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43munroll\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munroll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Example: Add another GRU layer if return_sequences=True\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_sequences:\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/keras/src/models/sequential.py:87\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer, rebuild)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_input_shape_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(\u001b[43mInputLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_shape_arg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# If we are passed a Keras tensor created by keras.Input(), we\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# extract the input layer from its keras history and use that.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_history\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:47\u001b[0m, in \u001b[0;36mInputLayer.__init__\u001b[0;34m(self, shape, batch_size, dtype, sparse, batch_shape, input_tensor, optional, name, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must pass a `shape` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     shape \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m (batch_size,) \u001b[38;5;241m+\u001b[39m shape\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_shape \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mstandardize_shape(batch_shape)\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/keras/src/backend/common/variables.py:515\u001b[0m, in \u001b[0;36mstandardize_shape\u001b[0;34m(shape)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUndefined shapes are not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(shape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__iter__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot convert \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to a shape.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mbackend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(shape, tf\u001b[38;5;241m.\u001b[39mTensorShape):\n\u001b[1;32m    518\u001b[0m         \u001b[38;5;66;03m# `tf.TensorShape` may contain `Dimension` objects.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m         \u001b[38;5;66;03m# We need to convert the items in it to either int or `None`\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert '<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x7a092874f370>' to a shape."
     ]
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "# Instantiate the tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    buildModelGRU,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuning',\n",
    "    project_name='gru_tuning'\n",
    ")\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(X_train, y_train, validation_data=(x_val, y_val), epochs=50)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # Metric to monitor\n",
    "    patience=50,                # Number of epochs with no improvement to wait before stopping\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best metric value\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN model for qb - split 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724968153.106032  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724968153.192230  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724968153.194314  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724968153.197365  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724968153.199205  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724968153.201112  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724968153.348964  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724968153.350600  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724968153.352695  324125 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-29 17:49:13.354632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5259 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:0a:00.0, compute capability: 8.6\n",
      "/home/calder/Documents/ff2024/ff24/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 17:49:15.504497: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 181.1431 - mae: 11.2297 - val_loss: 197.3822 - val_mae: 11.4894\n",
      "Epoch 2/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 163.4272 - mae: 10.6475 - val_loss: 173.0025 - val_mae: 10.6321\n",
      "Epoch 3/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 123.9740 - mae: 9.0060 - val_loss: 141.1855 - val_mae: 9.2538\n",
      "Epoch 4/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 83.7116 - mae: 7.2186 - val_loss: 101.9131 - val_mae: 7.8340\n",
      "Epoch 5/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 62.3418 - mae: 6.1742 - val_loss: 91.6439 - val_mae: 7.4598\n",
      "Epoch 6/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 52.0456 - mae: 5.7216 - val_loss: 86.4689 - val_mae: 7.3974\n",
      "Epoch 7/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 49.0523 - mae: 5.5493 - val_loss: 88.2716 - val_mae: 7.4934\n",
      "Epoch 8/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 49.7840 - mae: 5.6244 - val_loss: 94.7804 - val_mae: 7.7445\n",
      "Epoch 9/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 42.3969 - mae: 5.1902 - val_loss: 94.9105 - val_mae: 7.6634\n",
      "Epoch 10/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 41.6636 - mae: 5.1512 - val_loss: 99.6196 - val_mae: 7.8992\n",
      "Training RNN model for qb - split 2...\n",
      "Epoch 1/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 189.3742 - mae: 11.5380 - val_loss: 151.8325 - val_mae: 10.0940\n",
      "Epoch 2/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 129.1285 - mae: 9.1361 - val_loss: 76.2545 - val_mae: 6.8662\n",
      "Epoch 3/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 69.0895 - mae: 6.5064 - val_loss: 60.9375 - val_mae: 6.2690\n",
      "Epoch 4/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 58.9897 - mae: 6.1296 - val_loss: 61.4640 - val_mae: 6.2881\n",
      "Epoch 5/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 57.8415 - mae: 6.0424 - val_loss: 62.3267 - val_mae: 6.3563\n",
      "Epoch 6/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 53.5619 - mae: 5.8662 - val_loss: 61.3227 - val_mae: 6.3553\n",
      "Epoch 7/10\n",
      "\u001b[1m161/161\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 51.1619 - mae: 5.7100 - val_loss: 64.2441 - val_mae: 6.4351\n",
      "Training RNN model for qb - split 3...\n",
      "Epoch 1/10\n",
      "\u001b[1m242/242\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 195.8214 - mae: 11.8131 - val_loss: 93.0461 - val_mae: 7.5449\n",
      "Epoch 2/10\n",
      "\u001b[1m242/242\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 87.2759 - mae: 7.3779 - val_loss: 52.7228 - val_mae: 5.7797\n",
      "Epoch 3/10\n",
      "\u001b[1m242/242\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 61.0706 - mae: 6.2290 - val_loss: 52.5584 - val_mae: 5.8093\n",
      "Epoch 4/10\n",
      "\u001b[1m242/242\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 56.6124 - mae: 6.0141 - val_loss: 53.2855 - val_mae: 5.8752\n",
      "Epoch 5/10\n",
      "\u001b[1m242/242\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 53.5711 - mae: 5.8428 - val_loss: 54.2618 - val_mae: 5.9099\n",
      "Epoch 6/10\n",
      "\u001b[1m242/242\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 52.3054 - mae: 5.7555 - val_loss: 55.1768 - val_mae: 5.8661\n",
      "Epoch 7/10\n",
      "\u001b[1m242/242\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 51.3130 - mae: 5.7127 - val_loss: 55.2211 - val_mae: 5.9705\n",
      "Training RNN model for qb - split 4...\n",
      "Epoch 1/10\n",
      "\u001b[1m322/322\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 175.1633 - mae: 11.0558 - val_loss: 76.9577 - val_mae: 6.8428\n",
      "Epoch 2/10\n",
      "\u001b[1m322/322\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 65.1311 - mae: 6.3340 - val_loss: 58.9289 - val_mae: 6.1958\n",
      "Epoch 3/10\n",
      "\u001b[1m322/322\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 55.1361 - mae: 5.9141 - val_loss: 59.0826 - val_mae: 6.1646\n",
      "Epoch 4/10\n",
      "\u001b[1m322/322\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 54.3401 - mae: 5.8989 - val_loss: 61.2748 - val_mae: 6.2784\n",
      "Training RNN model for qb - split 5...\n",
      "Epoch 1/10\n",
      "\u001b[1m403/403\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 174.7952 - mae: 10.9664 - val_loss: 68.0495 - val_mae: 6.5590\n",
      "Epoch 2/10\n",
      "\u001b[1m403/403\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 62.1014 - mae: 6.2788 - val_loss: 67.5272 - val_mae: 6.5858\n",
      "Epoch 3/10\n",
      "\u001b[1m403/403\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 56.2533 - mae: 5.9971 - val_loss: 66.8573 - val_mae: 6.5360\n",
      "Epoch 4/10\n",
      "\u001b[1m403/403\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 54.1790 - mae: 5.8999 - val_loss: 67.5393 - val_mae: 6.5873\n",
      "Training RNN model for rb - split 1...\n",
      "Epoch 1/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 100.6951 - mae: 7.9628 - val_loss: 74.3066 - val_mae: 5.9218\n",
      "Epoch 2/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 59.1438 - mae: 5.6062 - val_loss: 45.6182 - val_mae: 4.9872\n",
      "Epoch 3/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 39.8879 - mae: 4.6144 - val_loss: 45.2296 - val_mae: 4.9246\n",
      "Epoch 4/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 39.1050 - mae: 4.6316 - val_loss: 47.3522 - val_mae: 5.0329\n",
      "Epoch 5/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 36.0145 - mae: 4.4655 - val_loss: 46.4567 - val_mae: 5.1941\n",
      "Epoch 6/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 37.2213 - mae: 4.5692 - val_loss: 46.2019 - val_mae: 5.0149\n",
      "Epoch 7/10\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 36.9547 - mae: 4.4928 - val_loss: 50.7221 - val_mae: 5.2638\n",
      "Training RNN model for rb - split 2...\n",
      "Epoch 1/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 91.4088 - mae: 7.2029 - val_loss: 49.0052 - val_mae: 5.0245\n",
      "Epoch 2/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 44.4932 - mae: 4.8587 - val_loss: 46.9087 - val_mae: 5.1566\n",
      "Epoch 3/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 39.1371 - mae: 4.5898 - val_loss: 47.2466 - val_mae: 5.1944\n",
      "Epoch 4/10\n",
      "\u001b[1m384/384\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 38.5973 - mae: 4.6097 - val_loss: 47.6960 - val_mae: 5.2191\n",
      "Training RNN model for rb - split 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 17:50:28.462832: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 893987976 exceeds 10% of free system memory.\n",
      "2024-08-29 17:50:29.243296: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 893987976 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 84.0391 - mae: 6.8404 - val_loss: 41.0235 - val_mae: 4.9112\n",
      "Epoch 2/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 42.4024 - mae: 4.8768 - val_loss: 41.6904 - val_mae: 4.9451\n",
      "Epoch 3/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 40.1407 - mae: 4.6918 - val_loss: 41.3636 - val_mae: 4.8714\n",
      "Epoch 4/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 39.4506 - mae: 4.6314 - val_loss: 41.7739 - val_mae: 4.8982\n",
      "Epoch 5/10\n",
      "\u001b[1m576/576\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 38.0016 - mae: 4.5227 - val_loss: 42.4491 - val_mae: 4.9834\n",
      "Training RNN model for rb - split 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 17:50:49.105145: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1191903048 exceeds 10% of free system memory.\n",
      "2024-08-29 17:50:50.179951: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1191903048 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m768/768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 79.9807 - mae: 6.6467 - val_loss: 44.5137 - val_mae: 5.1642\n",
      "Epoch 2/10\n",
      "\u001b[1m768/768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 42.4810 - mae: 4.8334 - val_loss: 43.9237 - val_mae: 5.0182\n",
      "Epoch 3/10\n",
      "\u001b[1m768/768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 40.5454 - mae: 4.7018 - val_loss: 44.2202 - val_mae: 5.0663\n",
      "Epoch 4/10\n",
      "\u001b[1m768/768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 37.6944 - mae: 4.5489 - val_loss: 44.8508 - val_mae: 5.1232\n",
      "Training RNN model for rb - split 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 17:51:12.611610: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1489818120 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m959/959\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 70.8190 - mae: 6.2258 - val_loss: 48.9341 - val_mae: 5.4183\n",
      "Epoch 2/10\n",
      "\u001b[1m959/959\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 42.8718 - mae: 4.8373 - val_loss: 48.1351 - val_mae: 5.3102\n",
      "Epoch 3/10\n",
      "\u001b[1m959/959\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 40.0570 - mae: 4.6472 - val_loss: 49.9197 - val_mae: 5.5094\n",
      "Epoch 4/10\n",
      "\u001b[1m959/959\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 38.6049 - mae: 4.5714 - val_loss: 50.3379 - val_mae: 5.5342\n",
      "Training RNN model for wr - split 1...\n",
      "Epoch 1/10\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 138.9602 - mae: 9.3756 - val_loss: 67.7253 - val_mae: 5.6471\n",
      "Epoch 2/10\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 70.6803 - mae: 6.1185 - val_loss: 48.1162 - val_mae: 5.1831\n",
      "Epoch 3/10\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 54.9385 - mae: 5.6915 - val_loss: 48.9281 - val_mae: 5.3889\n",
      "Epoch 4/10\n",
      "\u001b[1m245/245\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 53.5913 - mae: 5.6345 - val_loss: 49.1935 - val_mae: 5.4394\n",
      "Training RNN model for wr - split 2...\n",
      "Epoch 1/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 114.4631 - mae: 8.1718 - val_loss: 46.7625 - val_mae: 5.3057\n",
      "Epoch 2/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 52.1415 - mae: 5.4745 - val_loss: 47.6266 - val_mae: 5.3398\n",
      "Epoch 3/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 50.3252 - mae: 5.3934 - val_loss: 47.8592 - val_mae: 5.4020\n",
      "Epoch 4/10\n",
      "\u001b[1m489/489\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 49.5013 - mae: 5.3535 - val_loss: 48.2981 - val_mae: 5.3048\n",
      "Training RNN model for wr - split 3...\n",
      "Epoch 1/10\n",
      "\u001b[1m733/733\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 98.6372 - mae: 7.5268 - val_loss: 48.5761 - val_mae: 5.4645\n",
      "Epoch 2/10\n",
      "\u001b[1m733/733\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 50.1115 - mae: 5.3754 - val_loss: 49.7437 - val_mae: 5.4733\n",
      "Epoch 3/10\n",
      "\u001b[1m733/733\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 48.2850 - mae: 5.2910 - val_loss: 49.8943 - val_mae: 5.5843\n",
      "Epoch 4/10\n",
      "\u001b[1m733/733\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 45.9970 - mae: 5.1752 - val_loss: 50.7935 - val_mae: 5.6025\n",
      "Training RNN model for wr - split 4...\n",
      "Epoch 1/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 90.3543 - mae: 7.1899 - val_loss: 51.0680 - val_mae: 5.6032\n",
      "Epoch 2/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 48.9050 - mae: 5.3194 - val_loss: 52.0632 - val_mae: 5.5771\n",
      "Epoch 3/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 46.9229 - mae: 5.2153 - val_loss: 51.4513 - val_mae: 5.5008\n",
      "Epoch 4/10\n",
      "\u001b[1m978/978\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 46.6395 - mae: 5.2073 - val_loss: 52.4171 - val_mae: 5.6311\n",
      "Training RNN model for wr - split 5...\n",
      "Epoch 1/10\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 88.5864 - mae: 7.0328 - val_loss: 44.8664 - val_mae: 5.3687\n",
      "Epoch 2/10\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 48.4724 - mae: 5.3063 - val_loss: 45.6144 - val_mae: 5.4845\n",
      "Epoch 3/10\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 45.9965 - mae: 5.1746 - val_loss: 44.3779 - val_mae: 5.2728\n",
      "Epoch 4/10\n",
      "\u001b[1m1222/1222\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 45.3535 - mae: 5.0992 - val_loss: 43.6362 - val_mae: 5.1770\n",
      "Training RNN model for te - split 1...\n",
      "Epoch 1/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 48.9887 - mae: 5.2866 - val_loss: 46.1057 - val_mae: 4.7871\n",
      "Epoch 2/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 35.4058 - mae: 4.2203 - val_loss: 30.9778 - val_mae: 3.7942\n",
      "Epoch 3/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 26.3577 - mae: 3.5568 - val_loss: 29.9745 - val_mae: 3.8932\n",
      "Epoch 4/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 22.6274 - mae: 3.4000 - val_loss: 30.5938 - val_mae: 3.9582\n",
      "Epoch 5/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 23.4171 - mae: 3.4779 - val_loss: 28.8874 - val_mae: 3.9121\n",
      "Epoch 6/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 21.7633 - mae: 3.4220 - val_loss: 31.4991 - val_mae: 4.0246\n",
      "Epoch 7/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 20.4473 - mae: 3.2971 - val_loss: 30.9946 - val_mae: 3.9924\n",
      "Epoch 8/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.3821 - mae: 3.2507 - val_loss: 30.8941 - val_mae: 3.9719\n",
      "Epoch 9/10\n",
      "\u001b[1m120/120\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 19.5879 - mae: 3.2118 - val_loss: 33.4805 - val_mae: 4.0980\n",
      "Training RNN model for te - split 2...\n",
      "Epoch 1/10\n",
      "\u001b[1m239/239\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 55.7561 - mae: 5.6269 - val_loss: 37.4464 - val_mae: 4.2999\n",
      "Epoch 2/10\n",
      "\u001b[1m239/239\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 29.1344 - mae: 3.8481 - val_loss: 34.4404 - val_mae: 4.5761\n",
      "Epoch 3/10\n",
      "\u001b[1m239/239\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 24.5609 - mae: 3.6724 - val_loss: 31.1585 - val_mae: 4.3081\n",
      "Epoch 4/10\n",
      "\u001b[1m239/239\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 24.9890 - mae: 3.6706 - val_loss: 32.1312 - val_mae: 4.2937\n",
      "Training RNN model for te - split 3...\n",
      "Epoch 1/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 55.1031 - mae: 5.5619 - val_loss: 31.2119 - val_mae: 4.2105\n",
      "Epoch 2/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 28.4302 - mae: 3.9036 - val_loss: 30.9071 - val_mae: 4.2336\n",
      "Epoch 3/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 26.5965 - mae: 3.8572 - val_loss: 31.2158 - val_mae: 4.2838\n",
      "Epoch 4/10\n",
      "\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 25.8506 - mae: 3.7709 - val_loss: 32.4697 - val_mae: 4.4261\n",
      "Training RNN model for te - split 4...\n",
      "Epoch 1/10\n",
      "\u001b[1m478/478\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 52.2675 - mae: 5.3697 - val_loss: 31.4380 - val_mae: 4.1964\n",
      "Epoch 2/10\n",
      "\u001b[1m478/478\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 27.1879 - mae: 3.8839 - val_loss: 31.7383 - val_mae: 4.2413\n",
      "Epoch 3/10\n",
      "\u001b[1m478/478\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 26.2232 - mae: 3.8110 - val_loss: 31.8380 - val_mae: 4.2878\n",
      "Epoch 4/10\n",
      "\u001b[1m478/478\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 25.7717 - mae: 3.7690 - val_loss: 33.0006 - val_mae: 4.2763\n",
      "Training RNN model for te - split 5...\n",
      "Epoch 1/10\n",
      "\u001b[1m597/597\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 51.5122 - mae: 5.2856 - val_loss: 27.8345 - val_mae: 4.0521\n",
      "Epoch 2/10\n",
      "\u001b[1m597/597\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 28.2879 - mae: 3.9255 - val_loss: 27.7780 - val_mae: 3.9329\n",
      "Epoch 3/10\n",
      "\u001b[1m597/597\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 27.0618 - mae: 3.8265 - val_loss: 27.8311 - val_mae: 3.9990\n",
      "Epoch 4/10\n",
      "\u001b[1m597/597\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 27.1174 - mae: 3.8455 - val_loss: 27.5786 - val_mae: 3.9744\n",
      "Epoch 5/10\n",
      "\u001b[1m597/597\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 25.4893 - mae: 3.7417 - val_loss: 28.5945 - val_mae: 4.0956\n",
      "Epoch 6/10\n",
      "\u001b[1m597/597\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 25.0300 - mae: 3.6784 - val_loss: 28.8912 - val_mae: 4.1355\n",
      "Epoch 7/10\n",
      "\u001b[1m597/597\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 23.8462 - mae: 3.5933 - val_loss: 29.8936 - val_mae: 4.2316\n",
      "Epoch 8/10\n",
      "\u001b[1m597/597\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 22.9916 - mae: 3.5453 - val_loss: 30.7027 - val_mae: 4.2998\n"
     ]
    }
   ],
   "source": [
    "# run the model on the normalized datasets\n",
    "rnn_models_gru = {\n",
    "    'qb': [],\n",
    "    'rb': [],\n",
    "    'wr': [],\n",
    "    'te': []\n",
    "}\n",
    "\n",
    "for key, datasets in datasets.items():\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        print(f\"Training RNN model for {key} - split {i + 1}...\")\n",
    "        \n",
    "        # Get the input shape\n",
    "        input_shape = dataset['X_train'].shape[1:]\n",
    "        \n",
    "        # Create the RNN model\n",
    "        model = buildModelGRU(input_shape,\n",
    "                                units=512\n",
    "                                )\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            dataset['X_train'],\n",
    "            dataset['y_train'],\n",
    "            epochs=150,\n",
    "            batch_size=32,\n",
    "            validation_data=(dataset['X_test'], dataset['y_test']),\n",
    "            verbose=1,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        \n",
    "        # Store the model\n",
    "        rnn_models_gru[key].append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model tuning and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rnn_models_gru' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test the model on the test data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m rnn_predictions_gru \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqb\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwr\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m      7\u001b[0m }\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, models \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrnn_models_gru\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models):\n\u001b[1;32m     11\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m datasets[key][i]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rnn_models_gru' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the model on the test data\n",
    "rnn_predictions_gru = {\n",
    "    'qb': [],\n",
    "    'rb': [],\n",
    "    'wr': [],\n",
    "    'te': []\n",
    "}\n",
    "\n",
    "for key, models in rnn_models_gru.items():\n",
    "    for i, model in enumerate(models):\n",
    "        dataset = datasets[key][i]\n",
    "        print(f\"Testing RNN model for {key} - split {i + 1}...\")\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(dataset['X_test'])\n",
    "        \n",
    "        # Store the predictions\n",
    "        rnn_predictions_gru[key].append(y_pred)\n",
    "\n",
    "# Output the predictions\n",
    "for key, predictions in rnn_predictions_gru.items():\n",
    "    print(f\"Predictions for {key}:\")\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        print(f\"  Split {i + 1}:\")\n",
    "        print(f\"    Shape: {prediction.shape}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation\n",
    "\n",
    "#### RMSE\n",
    "#### MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_324125/624265048.py:56: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  pl.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation fmin which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 86\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Plot the heatmap\u001b[39;00m\n\u001b[1;32m     85\u001b[0m pl\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 86\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheatmap_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcoolwarm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.3f\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m pl\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSplit Number\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     89\u001b[0m pl\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosition\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/seaborn/matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[1;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/seaborn/matrix.py:163\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mylabel \u001b[38;5;241m=\u001b[39m ylabel \u001b[38;5;28;01mif\u001b[39;00m ylabel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# Determine good default values for the colormapping\u001b[39;00m\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_determine_cmap_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplot_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# Sort out the annotations\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m annot \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/seaborn/matrix.py:202\u001b[0m, in \u001b[0;36m_HeatMapper._determine_cmap_params\u001b[0;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[1;32m    200\u001b[0m         vmin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanpercentile(calc_data, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m         vmin \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vmax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m robust:\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:343\u001b[0m, in \u001b[0;36mnanmin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m    338\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhere\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m where\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(a) \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;129;01mand\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[39;00m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;66;03m# which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfmin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(res)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    345\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN slice encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[1;32m    346\u001b[0m                       stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation fmin which has no identity"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_predictions(y_true, y_pred, key, split):\n",
    "    pl.figure(figsize=(10, 6))\n",
    "    pl.scatter(y_true, y_pred, alpha=0.3)\n",
    "    pl.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    pl.xlabel('Actual')\n",
    "    pl.ylabel('Predicted')\n",
    "    pl.title(f'Predictions vs. Actuals for {key.upper()} - Split {split + 1}')\n",
    "    pl.grid(True)\n",
    "    pl.show()\n",
    "\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f'Mean Squared Error (MSE): {mse}')\n",
    "    print(f'Mean Absolute Error (MAE): {mae}')\n",
    "    print(f'RÂ² Score: {r2}')\n",
    "    return mse, mae, r2\n",
    "\n",
    "for key, predictions in rnn_predictions_gru.items():\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        dataset = datasets[key][i]\n",
    "        y_true = dataset['y_test']\n",
    "        y_pred = prediction\n",
    "\n",
    "        print(f\"Evaluating RNN model for {key} - split {i + 1}...\")\n",
    "        \n",
    "        # Plot Predictions vs. Actuals\n",
    "        plot_predictions(y_true, y_pred, key, i)\n",
    "\n",
    "        # Calculate and print evaluation metrics\n",
    "        mse, mae, r2 = evaluate_predictions(y_true, y_pred)\n",
    "\n",
    "        # Optionally, store the metrics for later comparison\n",
    "\n",
    "evaluation_results = {\n",
    "    'qb': [],\n",
    "    'rb': [],\n",
    "    'wr': [],\n",
    "    'te': []\n",
    "}\n",
    "\n",
    "for key, predictions in rnn_predictions_gru.items():\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        dataset = datasets[key][i]\n",
    "        y_true = dataset['y_test']\n",
    "        y_pred = prediction\n",
    "\n",
    "        mse, mae, r2 = evaluate_predictions(y_true, y_pred)\n",
    "        evaluation_results[key].append((mse, mae, r2))\n",
    "        \n",
    "pl.xlabel('Split Number')\n",
    "pl.ylabel('Mean Squared Error (MSE)')\n",
    "pl.title('MSE Across Splits for Each Position')\n",
    "pl.legend()\n",
    "pl.grid(True)\n",
    "pl.show()\n",
    "\n",
    "# Initialize the evaluation results dictionary\n",
    "evaluation_results = {\n",
    "    'qb': [],\n",
    "    'rb': [],\n",
    "    'wr': [],\n",
    "    'te': []\n",
    "}\n",
    "\n",
    "# Evaluate predictions and store the MSE, MAE, RÂ² score\n",
    "for key, predictions in rnn_predictions_gru.items():\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        dataset = datasets[key][i]\n",
    "        y_true = dataset['y_test']\n",
    "        y_pred = prediction\n",
    "\n",
    "        mse, mae, r2 = evaluate_predictions(y_true, y_pred)\n",
    "        evaluation_results[key].append(mse)  # Storing only MSE for heatmap\n",
    "\n",
    "# Convert the evaluation results into a DataFrame for heatmap plotting\n",
    "import pandas as pd\n",
    "\n",
    "# Convert evaluation results to a DataFrame\n",
    "heatmap_data = pd.DataFrame(evaluation_results)\n",
    "\n",
    "# Plot the heatmap\n",
    "pl.figure(figsize=(8, 6))\n",
    "sns.heatmap(heatmap_data.T, annot=True, cmap='coolwarm', fmt=\".3f\", cbar=True)\n",
    "\n",
    "pl.xlabel('Split Number')\n",
    "pl.ylabel('Position')\n",
    "pl.title('MSE Heatmap Across Splits and Positions')\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing feature importance for qb - split 1...\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step\n",
      "Computing feature importance for qb - split 2...\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 997us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step\n",
      "Computing feature importance for qb - split 3...\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Computing feature importance for qb - split 4...\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step\n",
      "Computing feature importance for qb - split 5...\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n",
      "\u001b[1m61/61\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n",
      "Computing feature importance for rb - split 1...\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Computing feature importance for rb - split 2...\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step\n",
      "Computing feature importance for rb - split 3...\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Computing feature importance for rb - split 4...\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step\n",
      "Computing feature importance for rb - split 5...\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Computing feature importance for wr - split 1...\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 994us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Computing feature importance for wr - split 2...\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "Computing feature importance for wr - split 3...\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 993us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step\n",
      "Computing feature importance for wr - split 4...\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step\n",
      "Computing feature importance for wr - split 5...\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step\n",
      "\u001b[1m179/179\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "Computing feature importance for te - split 1...\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 979us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Computing feature importance for te - split 2...\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step\n",
      "Computing feature importance for te - split 3...\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Computing feature importance for te - split 4...\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step\n",
      "Computing feature importance for te - split 5...\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step\n",
      "\u001b[1m91/91\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3, 1), indices imply (3, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Assuming all splits have the same number of features, create a DataFrame\u001b[39;00m\n\u001b[1;32m     38\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m---> 39\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimportance\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimportance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeature_importance_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Plot the feature importances as a heatmap\u001b[39;00m\n\u001b[1;32m     43\u001b[0m pl\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/pandas/core/frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[1;32m    825\u001b[0m         )\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (3, 1), indices imply (3, 3)"
     ]
    }
   ],
   "source": [
    "def compute_permutation_importance(model, X_test, y_test, n_repeats=5):\n",
    "    baseline_mse = mean_squared_error(y_test, model.predict(X_test))\n",
    "    importances = np.zeros(X_test.shape[1])\n",
    "\n",
    "    for i in range(X_test.shape[1]):\n",
    "        shuffled_mses = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_test_permuted = X_test.copy()\n",
    "            np.random.shuffle(X_test_permuted[:, i])\n",
    "            shuffled_mses.append(mean_squared_error(y_test, model.predict(X_test_permuted)))\n",
    "        \n",
    "        importances[i] = np.mean(shuffled_mses) - baseline_mse\n",
    "\n",
    "    return importances\n",
    "\n",
    "# Compute permutation feature importance for each model and each split\n",
    "feature_importance_results = {\n",
    "    'qb': [],\n",
    "    'rb': [],\n",
    "    'wr': [],\n",
    "    'te': []\n",
    "}\n",
    "\n",
    "for key, models in rnn_models_gru.items():\n",
    "    for i, model in enumerate(models):\n",
    "        dataset = normalized_datasets[key][i]\n",
    "        X_test = dataset['X_test']\n",
    "        y_test = dataset['y_test']\n",
    "\n",
    "        print(f\"Computing feature importance for {key} - split {i + 1}...\")\n",
    "        importances = compute_permutation_importance(model, X_test, y_test)\n",
    "        feature_importance_results[key].append(importances)\n",
    "\n",
    "# Convert feature importance results to DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming all splits have the same number of features, create a DataFrame\n",
    "feature_names = [f'Feature_{j}' for j in range(X_test.shape[1])]\n",
    "importance_df = pd.DataFrame(np.mean(np.array([np.array(importance).T for importance in feature_importance_results[key]]), axis=0),\n",
    "                             columns=feature_names)\n",
    "\n",
    "# Plot the feature importances as a heatmap\n",
    "pl.figure(figsize=(12, 8))\n",
    "sns.heatmap(importance_df, annot=True, cmap='viridis', fmt=\".3f\", cbar=True)\n",
    "\n",
    "pl.xlabel('Features')\n",
    "pl.ylabel('Position')\n",
    "pl.title('Permutation Feature Importance Heatmap')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
