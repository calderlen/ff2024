{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-26 18:27:37.355838: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-26 18:27:37.368223: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-26 18:27:37.371665: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-26 18:27:37.382000: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-26 18:27:38.036509: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/player_stats.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_id                       object\n",
       "player_name                     object\n",
       "player_display_name             object\n",
       "position                        object\n",
       "position_group                  object\n",
       "headshot_url                    object\n",
       "recent_team                     object\n",
       "season                           int64\n",
       "week                             int64\n",
       "season_type                     object\n",
       "opponent_team                   object\n",
       "completions                      int64\n",
       "attempts                         int64\n",
       "passing_yards                    int64\n",
       "passing_tds                      int64\n",
       "interceptions                    int64\n",
       "sacks                            int64\n",
       "sack_yards                       int64\n",
       "sack_fumbles                     int64\n",
       "sack_fumbles_lost                int64\n",
       "passing_air_yards                int64\n",
       "passing_yards_after_catch        int64\n",
       "passing_first_downs              int64\n",
       "passing_epa                    float64\n",
       "passing_2pt_conversions          int64\n",
       "pacr                           float64\n",
       "dakota                         float64\n",
       "carries                          int64\n",
       "rushing_yards                    int64\n",
       "rushing_tds                      int64\n",
       "rushing_fumbles                  int64\n",
       "rushing_fumbles_lost             int64\n",
       "rushing_first_downs              int64\n",
       "rushing_epa                    float64\n",
       "rushing_2pt_conversions          int64\n",
       "receptions                       int64\n",
       "targets                          int64\n",
       "receiving_yards                  int64\n",
       "receiving_tds                    int64\n",
       "receiving_fumbles                int64\n",
       "receiving_fumbles_lost           int64\n",
       "receiving_air_yards              int64\n",
       "receiving_yards_after_catch      int64\n",
       "receiving_first_downs            int64\n",
       "receiving_epa                  float64\n",
       "receiving_2pt_conversions        int64\n",
       "racr                           float64\n",
       "target_share                   float64\n",
       "air_yards_share                float64\n",
       "wopr                           float64\n",
       "special_teams_tds                int64\n",
       "fantasy_points                 float64\n",
       "fantasy_points_ppr             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(positions, years):\n",
    "    # Initialize an empty dictionary to store DataFrames by position\n",
    "    data_dict = {}\n",
    "    \n",
    "    for position in positions:\n",
    "        # Initialize an empty list to collect DataFrames for each year\n",
    "        df_list = []\n",
    "        \n",
    "        for year in years:\n",
    "            filepath = f'NFL-data-Players/{year}/{position}_season.csv'\n",
    "            df = pd.read_csv(filepath)\n",
    "            df['Year'] = year\n",
    "            df_list.append(df)\n",
    "        \n",
    "        # Concatenate all yearly DataFrames into a single DataFrame for the current position\n",
    "        position_data = pd.concat(df_list, ignore_index=True)\n",
    "        position_data = position_data.fillna(0)\n",
    "        \n",
    "        # Store the DataFrame in the dictionary with position as the key\n",
    "        data_dict[position] = position_data\n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_id</th>\n",
       "      <th>player_name</th>\n",
       "      <th>player_display_name</th>\n",
       "      <th>position</th>\n",
       "      <th>position_group</th>\n",
       "      <th>headshot_url</th>\n",
       "      <th>recent_team</th>\n",
       "      <th>season</th>\n",
       "      <th>week</th>\n",
       "      <th>season_type</th>\n",
       "      <th>...</th>\n",
       "      <th>receiving_first_downs</th>\n",
       "      <th>receiving_epa</th>\n",
       "      <th>receiving_2pt_conversions</th>\n",
       "      <th>racr</th>\n",
       "      <th>target_share</th>\n",
       "      <th>air_yards_share</th>\n",
       "      <th>wopr</th>\n",
       "      <th>special_teams_tds</th>\n",
       "      <th>fantasy_points</th>\n",
       "      <th>fantasy_points_ppr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.292378</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1999</td>\n",
       "      <td>2</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377009</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1999</td>\n",
       "      <td>4</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.699578</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1999</td>\n",
       "      <td>7</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.228454</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00-0000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abdul-Karim al-Jabbar</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1999</td>\n",
       "      <td>8</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128868</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>14</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.787724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>-0.025532</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128869</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>15</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.442067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.055736</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128870</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>16</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.961893</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.056034</td>\n",
       "      <td>0.044109</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128871</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.644468</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.057778</td>\n",
       "      <td>0.267717</td>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128872</th>\n",
       "      <td>00-0039165</td>\n",
       "      <td>Z.Charbonnet</td>\n",
       "      <td>Zach Charbonnet</td>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>https://static.www.nfl.com/image/private/f_aut...</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2023</td>\n",
       "      <td>18</td>\n",
       "      <td>REG</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.740490</td>\n",
       "      <td>0</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.031447</td>\n",
       "      <td>0.137397</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128873 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         player_id   player_name    player_display_name position  \\\n",
       "0       00-0000003           NaN  Abdul-Karim al-Jabbar       RB   \n",
       "1       00-0000003           NaN  Abdul-Karim al-Jabbar       RB   \n",
       "2       00-0000003           NaN  Abdul-Karim al-Jabbar       RB   \n",
       "3       00-0000003           NaN  Abdul-Karim al-Jabbar       RB   \n",
       "4       00-0000003           NaN  Abdul-Karim al-Jabbar       RB   \n",
       "...            ...           ...                    ...      ...   \n",
       "128868  00-0039165  Z.Charbonnet        Zach Charbonnet       RB   \n",
       "128869  00-0039165  Z.Charbonnet        Zach Charbonnet       RB   \n",
       "128870  00-0039165  Z.Charbonnet        Zach Charbonnet       RB   \n",
       "128871  00-0039165  Z.Charbonnet        Zach Charbonnet       RB   \n",
       "128872  00-0039165  Z.Charbonnet        Zach Charbonnet       RB   \n",
       "\n",
       "       position_group                                       headshot_url  \\\n",
       "0                  RB                                                NaN   \n",
       "1                  RB                                                NaN   \n",
       "2                  RB                                                NaN   \n",
       "3                  RB                                                NaN   \n",
       "4                  RB                                                NaN   \n",
       "...               ...                                                ...   \n",
       "128868             RB  https://static.www.nfl.com/image/private/f_aut...   \n",
       "128869             RB  https://static.www.nfl.com/image/private/f_aut...   \n",
       "128870             RB  https://static.www.nfl.com/image/private/f_aut...   \n",
       "128871             RB  https://static.www.nfl.com/image/private/f_aut...   \n",
       "128872             RB  https://static.www.nfl.com/image/private/f_aut...   \n",
       "\n",
       "       recent_team  season  week season_type  ... receiving_first_downs  \\\n",
       "0              MIA    1999     1         REG  ...                     0   \n",
       "1              MIA    1999     2         REG  ...                     1   \n",
       "2              MIA    1999     4         REG  ...                     0   \n",
       "3              CLE    1999     7         REG  ...                     0   \n",
       "4              CLE    1999     8         REG  ...                     0   \n",
       "...            ...     ...   ...         ...  ...                   ...   \n",
       "128868         SEA    2023    14         REG  ...                     0   \n",
       "128869         SEA    2023    15         REG  ...                     0   \n",
       "128870         SEA    2023    16         REG  ...                     0   \n",
       "128871         SEA    2023    17         REG  ...                     2   \n",
       "128872         SEA    2023    18         REG  ...                     2   \n",
       "\n",
       "        receiving_epa  receiving_2pt_conversions      racr  target_share  \\\n",
       "0            0.292378                          0  0.000000      0.052632   \n",
       "1            0.377009                          0  0.000000      0.117647   \n",
       "2           -0.699578                          0       NaN      0.023810   \n",
       "3           -0.228454                          0  0.000000      0.050000   \n",
       "4                 NaN                          0       NaN           NaN   \n",
       "...               ...                        ...       ...           ...   \n",
       "128868      -0.787724                          0 -0.666667      0.032258   \n",
       "128869      -0.442067                          0  0.000000      0.031250   \n",
       "128870      -1.961893                          0  0.307692      0.055556   \n",
       "128871       1.644468                          0  3.000000      0.151515   \n",
       "128872       1.740490                          0  5.600000      0.076923   \n",
       "\n",
       "        air_yards_share      wopr  special_teams_tds  fantasy_points  \\\n",
       "0                   NaN       NaN                  0            12.7   \n",
       "1                   NaN       NaN                  0             5.1   \n",
       "2                   NaN       NaN                  0             0.2   \n",
       "3                   NaN       NaN                  0             3.5   \n",
       "4                   NaN       NaN                  0             3.9   \n",
       "...                 ...       ...                ...             ...   \n",
       "128868        -0.025532  0.030515                  0             4.8   \n",
       "128869         0.012658  0.055736                  0             1.6   \n",
       "128870        -0.056034  0.044109                  0            -0.4   \n",
       "128871         0.057778  0.267717                  0             4.1   \n",
       "128872         0.031447  0.137397                  0             6.0   \n",
       "\n",
       "        fantasy_points_ppr  \n",
       "0                     13.7  \n",
       "1                      8.1  \n",
       "2                      0.2  \n",
       "3                      5.5  \n",
       "4                      3.9  \n",
       "...                    ...  \n",
       "128868                 5.8  \n",
       "128869                 1.6  \n",
       "128870                 0.6  \n",
       "128871                 9.1  \n",
       "128872                 8.0  \n",
       "\n",
       "[128873 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player_id                           0\n",
       "player_name                     67380\n",
       "player_display_name                 3\n",
       "position                           72\n",
       "position_group                     72\n",
       "headshot_url                    59092\n",
       "recent_team                         0\n",
       "season                              0\n",
       "week                                0\n",
       "season_type                         0\n",
       "opponent_team                       0\n",
       "completions                         0\n",
       "attempts                            0\n",
       "passing_yards                       0\n",
       "passing_tds                         0\n",
       "interceptions                       0\n",
       "sacks                               0\n",
       "sack_yards                          0\n",
       "sack_fumbles                        0\n",
       "sack_fumbles_lost                   0\n",
       "passing_air_yards                   0\n",
       "passing_yards_after_catch           0\n",
       "passing_first_downs                 0\n",
       "passing_epa                    112406\n",
       "passing_2pt_conversions             0\n",
       "pacr                           112846\n",
       "dakota                         114413\n",
       "carries                             0\n",
       "rushing_yards                       0\n",
       "rushing_tds                         0\n",
       "rushing_fumbles                     0\n",
       "rushing_fumbles_lost                0\n",
       "rushing_first_downs                 0\n",
       "rushing_epa                     75551\n",
       "rushing_2pt_conversions             0\n",
       "receptions                          0\n",
       "targets                             0\n",
       "receiving_yards                     0\n",
       "receiving_tds                       0\n",
       "receiving_fumbles                   0\n",
       "receiving_fumbles_lost              0\n",
       "receiving_air_yards                 0\n",
       "receiving_yards_after_catch         0\n",
       "receiving_first_downs               0\n",
       "receiving_epa                   26324\n",
       "receiving_2pt_conversions           0\n",
       "racr                            29109\n",
       "target_share                    26324\n",
       "air_yards_share                 52951\n",
       "wopr                            52951\n",
       "special_teams_tds                   0\n",
       "fantasy_points                      0\n",
       "fantasy_points_ppr                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling average of last 4 weeks\n",
    "# season-to-date stats\n",
    "# trend analysis\n",
    "# week to wee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full df cleaning\n",
    "df.drop(\n",
    "    columns=[\n",
    "        'headshot_url',\n",
    "        'player_name',\n",
    "        'player_display_name',\n",
    "        'recent_team',\n",
    "        'opponent_team',\n",
    "        'position'],\n",
    "    inplace=True\n",
    ")\n",
    "# Drop any rows with season=\"POST\"\n",
    "df = df[df['season_type'] != 'POST']\n",
    "\n",
    "df = df.sort_values(by=['player_id', 'season', 'week'])\n",
    "target = 'fantasy_points_ppr'\n",
    "\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=['player_id','season']\n",
    ")\n",
    "\n",
    "# QB data cleaning\n",
    "qb_df = df[df['position_group'] == 'QB'].copy()\n",
    "\n",
    "qb_df = pd.get_dummies(\n",
    "    qb_df,\n",
    "    columns=['position_group']\n",
    ")\n",
    "\n",
    "\n",
    "qb_df.drop(\n",
    "    columns=[\n",
    "        'receiving_epa',\n",
    "        'racr',\n",
    "        'target_share',\n",
    "        'air_yards_share',\n",
    "        'wopr'\n",
    "    ], inplace=True\n",
    ")\n",
    "qb_df.dropna(\n",
    "    subset=[\n",
    "        'passing_epa',\n",
    "        'pacr',\n",
    "        'dakota',\n",
    "        'rushing_epa'\n",
    "    ], inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "qb_df_target = qb_df[target]\n",
    "qb_df_features = qb_df.drop(columns=[target])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RB data cleaning\n",
    "\n",
    "rb_df = df[df['position_group'] == 'RB'].copy()\n",
    "\n",
    "rb_df = pd.get_dummies(\n",
    "    rb_df,\n",
    "    columns=['position_group']\n",
    ")\n",
    "\n",
    "rb_df.drop(\n",
    "    columns=[\n",
    "        'passing_epa',\n",
    "        'pacr',\n",
    "        'dakota',\n",
    "        'receiving_epa',\n",
    "        'rushing_epa',\n",
    "        'racr',\n",
    "        'target_share',\n",
    "        'air_yards_share',\n",
    "        'wopr'\n",
    "    ], inplace=True\n",
    ")\n",
    "\n",
    "rb_df_target = rb_df[target]\n",
    "rb_df_features = rb_df.drop(columns=[target])\n",
    "\n",
    "\n",
    "\n",
    "# WR data cleaning\n",
    "wr_df = df[df['position_group'] == 'WR'].copy()\n",
    "\n",
    "wr_df = pd.get_dummies(\n",
    "    wr_df,\n",
    "    columns=['position_group']\n",
    ")\n",
    "\n",
    "wr_df.drop(\n",
    "    columns=[\n",
    "        'passing_epa',\n",
    "        'pacr',\n",
    "        'dakota',\n",
    "        'rushing_epa',\n",
    "    ], inplace=True\n",
    ")\n",
    "\n",
    "wr_df.dropna(\n",
    "    subset=[\n",
    "        'receiving_epa',\n",
    "        'racr',\n",
    "        'target_share',\n",
    "        'air_yards_share',\n",
    "        'wopr'\n",
    "    ], inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "wr_df_target = wr_df[target]\n",
    "wr_df_features = wr_df.drop(columns=[target])\n",
    "\n",
    "\n",
    "\n",
    "# TE data cleaning\n",
    "te_df = df[df['position_group'] == 'TE'].copy()\n",
    "\n",
    "te_df = pd.get_dummies(\n",
    "    te_df,\n",
    "    columns=['position_group']\n",
    ")\n",
    "\n",
    "te_df.drop(\n",
    "    columns=[\n",
    "        'passing_epa',\n",
    "        'pacr',\n",
    "        'dakota',\n",
    "        'rushing_epa',\n",
    "    ], inplace=True\n",
    ")\n",
    "\n",
    "te_df.dropna(\n",
    "    subset=[\n",
    "        'receiving_epa',\n",
    "        'racr',\n",
    "        'target_share',\n",
    "        'air_yards_share',\n",
    "        'wopr'\n",
    "    ], inplace=True\n",
    ")\n",
    "\n",
    "te_df_target = te_df[target]\n",
    "te_df_features = te_df.drop(columns=[target])\n",
    "\n",
    "\n",
    "\n",
    "#sequence_length = 4  # Example: 4 weeks of data\n",
    "#X_qb, y_qb = create_sequences(np.hstack((qb_features, qb_target.reshape(-1, 1))), sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['position_group', 'week', 'season_type', 'completions', 'attempts',\n",
       "       'passing_yards', 'passing_tds', 'interceptions', 'sacks', 'sack_yards',\n",
       "       ...\n",
       "       'season_2014', 'season_2015', 'season_2016', 'season_2017',\n",
       "       'season_2018', 'season_2019', 'season_2020', 'season_2021',\n",
       "       'season_2022', 'season_2023'],\n",
       "      dtype='object', length=4045)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['week', 'season_type', 'completions', 'attempts', 'passing_yards',\n",
       "       'passing_tds', 'interceptions', 'sacks', 'sack_yards', 'sack_fumbles',\n",
       "       ...\n",
       "       'season_2015', 'season_2016', 'season_2017', 'season_2018',\n",
       "       'season_2019', 'season_2020', 'season_2021', 'season_2022',\n",
       "       'season_2023', 'position_group_QB'],\n",
       "      dtype='object', length=4040)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qb_df_features_encoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mqb_df_features_encoded\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qb_df_features_encoded' is not defined"
     ]
    }
   ],
   "source": [
    "qb_df_features_encoded.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(features, target, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - sequence_length):\n",
    "        X.append(features[i:i+sequence_length])\n",
    "        y.append(target[i+sequence_length])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))  # Optional dropout layer for regularization\n",
    "    model.add(Dense(1))  # Output layer for regression\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['recent_team', 'week', 'season_type', 'completions', 'attempts',\n",
       "       'passing_yards', 'passing_tds', 'interceptions', 'sacks', 'sack_yards',\n",
       "       ...\n",
       "       'season_2014', 'season_2015', 'season_2016', 'season_2017',\n",
       "       'season_2018', 'season_2019', 'season_2020', 'season_2021',\n",
       "       'season_2022', 'season_2023'],\n",
       "      dtype='object', length=401)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_df_features_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4  # Example: 4 weeks of data\n",
    "\n",
    "qb_features_sequences, qb_target_sequences = create_sequences(qb_df_features.values, qb_df_target.values, sequence_length)\n",
    "rb_features_sequences, rb_target_sequences = create_sequences(rb_df_features.values, rb_df_target.values, sequence_length)\n",
    "wr_features_sequences, wr_target_sequences = create_sequences(wr_df_features.values, wr_df_target.values, sequence_length)\n",
    "te_features_sequences, te_target_sequences = create_sequences(te_df_features.values, te_df_target.values, sequence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'REG'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[207], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply standardization (zero mean, unit variance)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[0;32m----> 4\u001b[0m qb_features_sequences \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqb_features_sequences\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqb_df_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(qb_features_sequences\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m rb_features_sequences \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(rb_features_sequences\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, rb_df_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mreshape(rb_features_sequences\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      6\u001b[0m wr_features_sequences \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(wr_features_sequences\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, wr_df_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mreshape(wr_features_sequences\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m \n\u001b[1;32m    884\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    913\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 914\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    921\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/sklearn/utils/validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ff2024/ff24/lib/python3.10/site-packages/sklearn/utils/_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'REG'"
     ]
    }
   ],
   "source": [
    "# Apply standardization (zero mean, unit variance)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "qb_features_sequences = scaler.fit_transform(qb_features_sequences.reshape(-1, qb_df_features.shape[1])).reshape(qb_features_sequences.shape)\n",
    "rb_features_sequences = scaler.fit_transform(rb_features_sequences.reshape(-1, rb_df_features.shape[1])).reshape(rb_features_sequences.shape)\n",
    "wr_features_sequences = scaler.fit_transform(wr_features_sequences.reshape(-1, wr_df_features.shape[1])).reshape(wr_features_sequences.shape)\n",
    "te_features_sequences = scaler.fit_transform(te_features_sequences.reshape(-1, te_df_features.shape[1])).reshape(te_features_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/validation/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance\n",
    "\n",
    "#### RMSE\n",
    "#### MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
